{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77491ad-19cb-4704-aa60-88b55f7226a7",
   "metadata": {},
   "source": [
    "# Main NoteBook - Random Walk + AprilTag Detection + Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a6c525f-8a58-47cc-bdd4-66279e42703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from random import randint\n",
    "import asyncio\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import cv2                                # state of the art computer vision algorithms library\n",
    "import numpy as np                        # fundamental package for scientific computing\n",
    "import matplotlib.pyplot as plt           # 2D plotting library producing publication quality figures\n",
    "import pyrealsense2 as rs                 # Intel RealSense cross-platform open-source API\n",
    "from pyapriltags import Detector\n",
    "\n",
    "\n",
    "from unitree_sdk2py.core.channel import ChannelSubscriber, ChannelFactoryInitialize\n",
    "from unitree_sdk2py.idl.default import unitree_go_msg_dds__SportModeState_\n",
    "from unitree_sdk2py.idl.unitree_go.msg.dds_ import SportModeState_\n",
    "from unitree_sdk2py.go2.video.video_client import VideoClient\n",
    "from unitree_sdk2py.go2.sport.sport_client import (\n",
    "    SportClient,\n",
    "    PathPoint,\n",
    "    SPORT_PATH_POINT_SIZE,\n",
    ")\n",
    "from unitree_sdk2py.go2.obstacles_avoid.obstacles_avoid_client import ObstaclesAvoidClient\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "710915f0-7248-434e-98b4-b3ed4a88dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for add on camera\n",
    "ChannelFactoryInitialize(0, \"eth0\")\n",
    "# ChannelFactoryInitialize()\n",
    "\n",
    "sport_client = SportClient()  \n",
    "sport_client.SetTimeout(10.0)\n",
    "sport_client.Init()\n",
    "\n",
    "obsclient = ObstaclesAvoidClient()\n",
    "obsclient.SetTimeout(3.0)\n",
    "obsclient.Init()\n",
    "\n",
    "# setup for default camera\n",
    "client = VideoClient()\n",
    "client.SetTimeout(1.0)\n",
    "client.Init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf2a6089-0756-47c1-ac5d-aa5f1b0fd6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_detector = Detector(families='tag36h11',\n",
    "                       nthreads=1,\n",
    "                       quad_decimate=1.0,\n",
    "                       quad_sigma=0.0,\n",
    "                       refine_edges=1,\n",
    "                       decode_sharpening=0.25,\n",
    "                       debug=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a7a02a2-dffb-4a37-acf1-1cc7c50da620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_randomly(vx=0.3, vy=0.3, vyaw=0.3):\n",
    "    obsclient.UseRemoteCommandFromApi(True)\n",
    "    obsclient.Move(vx, vy, vyaw)\n",
    "    time.sleep(1)\n",
    "\n",
    "def stop_move():\n",
    "    obsclient.Move(0.0, 0, 0)\n",
    "    obsclient.UseRemoteCommandFromApi(False)\n",
    "    time.sleep(1)\n",
    "\n",
    "def act(code):\n",
    "    stop_move()\n",
    "    sport_client.BalanceStand()\n",
    "    time.sleep(1)\n",
    "    if code == 0:\n",
    "        # hello\n",
    "        sport_client.Hello()\n",
    "    elif code == 1:\n",
    "        sport_client.Heart()\n",
    "    elif code == 2:\n",
    "        sport_client.Stretch()\n",
    "        time.sleep(2)\n",
    "    elif code == 3:\n",
    "        sport_client.WiggleHips()\n",
    "        time.sleep(5)\n",
    "    elif code == 4:\n",
    "        sport_client.StandDown()\n",
    "        time.sleep(2)\n",
    "        sport_client.StandUp()\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        return\n",
    "   \n",
    "    #end\n",
    "    time.sleep(1)\n",
    "    sport_client.BalanceStand()\n",
    "    time.sleep(1)\n",
    "    move_randomly()\n",
    "    time.sleep(3)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c324bd-a2b5-42ee-8538-686ed7efee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera Setup:\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "profile = pipe.start(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "515a2bc7-9e17-4cd0-853f-ccd3755fb3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DISTANCE = 400\n",
    "\n",
    "# def get \n",
    "\n",
    "def go_back():\n",
    "    while dist < MIN_DISTANCE:\n",
    "        obsclient.UseRemoteCommandFromApi(True)\n",
    "        obsclient.Move(-0.1, 0, 0)\n",
    "        distance = get_distance()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8fca35e-ae4f-4e9a-b47e-0893ad19d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_tag_from_main_camera():\n",
    "    # feed from default camera\n",
    "    code,data = client.GetImageSample()\n",
    "    img_1 = np.frombuffer(bytes(data), dtype=np.uint8)\n",
    "    image_1 = cv2.imdecode(img_1, cv2.IMREAD_COLOR)\n",
    "    image_1_gray = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "    clear_output(wait=True)\n",
    "    # plt.imshow(image_1_gray, cmap=\"gray\")\n",
    "    # plt.show()\n",
    "    tags = at_detector.detect(image_1_gray)\n",
    "    return tags\n",
    "    # return [t.tag_id for t in tags]\n",
    "    \n",
    "\n",
    "def detect_tag():\n",
    "    frameset = pipe.wait_for_frames()\n",
    "    color_frame = frameset.get_color_frame()\n",
    "    color_rgb = np.asanyarray(color_frame.get_data())\n",
    "    center_crop = color_rgb[:,240:-240,:]\n",
    "    center_crop_gray = cv2.cvtColor(center_crop, cv2.COLOR_RGB2GRAY)\n",
    "    tags = at_detector.detect(center_crop_gray)\n",
    "    return [t.tag_id for t in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f39f92-93fa-4579-b1c0-e543598b146f",
   "metadata": {},
   "outputs": [],
   "source": [
    " while True:\n",
    "     \n",
    "    # r = (np.random.random(3)-0.5)*0.8\n",
    "    # move_randomly(*r)\n",
    "    tags = detect_tag()\n",
    "    tags_2 = detect_tag_from_main_camera()\n",
    "    if len(tags_2) > 0:\n",
    "        print(len(sorted(tags_2)))\n",
    "        # break\n",
    "    \n",
    "    if len(tags) > 0:\n",
    "        act(tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eed046d9-3fa8-4752-9859-dbafc97c709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dfb72e0-7fe4-4188-8a36-bca23095b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_black_block_bottom(image):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # # Focus only on the bottom part (e.g., last 100 pixels)\n",
    "    # roi_height = 100  # Adjustable based on expected block size\n",
    "    # roi = image[height - roi_height:height, :]\n",
    "    \n",
    "    # Convert to grayscale and apply threshold\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 50, 50, cv2.THRESH_BINARY_INV)  # Detect dark regions\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [c for c in contours if cv2.boundingRect(c)[2] > 0.2*width and cv2.boundingRect(c)[1] > 0.7*height and  cv2.boundingRect(c)[3] > 100]\n",
    "    cv2.drawContours(image, contours, -1, (0, 255, 0), 2)\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Check if the detected block spans most of the width (e.g., 80% or more)\n",
    "        if w >= 0.5 * width and x > gray.shape[0]//2:\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(image, \"Black Block Detected\", (50, height - 150),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "            print(\"Black block detected at the bottom!\")\n",
    "            break\n",
    "\n",
    "    return image, contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e8f9257-8d38-4f2e-81a9-87b8248f4002",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detect_black_block_bottom' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m rect_x1, rect_y1 \u001b[38;5;241m=\u001b[39m margin, \u001b[38;5;241m400\u001b[39m\n\u001b[1;32m     19\u001b[0m rect_x2, rect_y2 \u001b[38;5;241m=\u001b[39m width \u001b[38;5;241m-\u001b[39m margin, height\n\u001b[0;32m---> 22\u001b[0m detected_image, contours \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_black_block_bottom\u001b[49m(image_1)\n\u001b[1;32m     24\u001b[0m cv2\u001b[38;5;241m.\u001b[39mrectangle(image_1, (rect_x1, rect_y1), (rect_x2, rect_y2), (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Check if any edge of the object is outside the rectangle\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'detect_black_block_bottom' is not defined"
     ]
    }
   ],
   "source": [
    "move_randomly(0.1, 0, 0)\n",
    "while True:\n",
    "    # feed from default camera\n",
    "    code,data = client.GetImageSample()\n",
    "    img_1 = np.frombuffer(bytes(data), dtype=np.uint8)\n",
    "    image_1 = cv2.imdecode(img_1, cv2.IMREAD_COLOR)\n",
    "    image_1_rgb = cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    image_1_gray = gray = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)  # Invert for black detection\n",
    "    \n",
    "    \n",
    "    # Get frame dimensions\n",
    "    height, width, _ = image_1.shape\n",
    "    \n",
    "    # Define white rectangle (200 pixels from each side)\n",
    "    margin = 200\n",
    "    rect_x1, rect_y1 = margin, 400\n",
    "    rect_x2, rect_y2 = width - margin, height\n",
    "\n",
    "    \n",
    "    detected_image, contours = detect_black_block_bottom(image_1)\n",
    "    \n",
    "    cv2.rectangle(image_1, (rect_x1, rect_y1), (rect_x2, rect_y2), (255, 255, 255), 2)\n",
    "    \n",
    "    # Check if any edge of the object is outside the rectangle\n",
    "    if contours:\n",
    "        print(len(contours))\n",
    "        max_contour = max(contours, key=cv2.contourArea, default=None)\n",
    "        x, y, w, h = cv2.boundingRect(max_contour)\n",
    "        # if x < rect_x1 or (x + w) > rect_x2 or y < rect_y1 or (y + h) > rect_y2: # if condition for entire object to be present inside\n",
    "        if y > rect_y2:\n",
    "            cv2.putText(detected_image, \"Object Outside!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 255, 255), 3)\n",
    "            print(\"Warning: Object is outside the safe area!\")\n",
    "            # move_randomly(-0.1, 0, 0)\n",
    "            # time.sleep(1)\n",
    "        else:\n",
    "            cv2.putText(detected_image, \"Object Inside!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 255, 255), 3)\n",
    "            print(\"Object inside\")\n",
    "            move_randomly(0.1, 0, 0)\n",
    "    else:\n",
    "        move_randomly(-0.1, 0, 0)\n",
    "        time.sleep(1)\n",
    "    clear_output(wait=True)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20,12))\n",
    "    ax[0].imshow(image_1_rgb)\n",
    "    ax[1].imshow(detected_image)\n",
    "    plt.show()\n",
    "    # time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a15ab858-7825-4763-8d4f-303a3ad9e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_move()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962cbc85-149b-4bea-abc4-164903bb0622",
   "metadata": {},
   "source": [
    "# Using AprilTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "484772db-dc25-495a-8cd7-2069bad2407b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m850\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# # feed from default camera\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# code,data = client.GetImageSample()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# img_1 = np.frombuffer(bytes(data), dtype=np.uint8)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# image_1 = cv2.imdecode(img_1, cv2.IMREAD_COLOR)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# image_1_rgb = cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     tags_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_tag_from_main_camera\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tags_2:\n\u001b[1;32m     13\u001b[0m         max_bottom_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1080\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m, in \u001b[0;36mdetect_tag_from_main_camera\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# plt.imshow(image_1_gray, cmap=\"gray\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[43mat_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_1_gray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tags\n",
      "File \u001b[0;32m~/jetbot/.jetbotenv/lib/python3.8/site-packages/pyapriltags/apriltags.py:361\u001b[0m, in \u001b[0;36mDetector.detect\u001b[0;34m(self, img, estimate_tag_pose, camera_params, tag_size)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo DLL found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# detect apriltags in the image\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapriltag_detector_detect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag_detector_ptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m apriltag \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mPOINTER(_ApriltagDetection)()\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, detections\u001b[38;5;241m.\u001b[39mcontents\u001b[38;5;241m.\u001b[39msize):\n\u001b[1;32m    366\u001b[0m \n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# extract the data for each apriltag that was identified\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "move_randomly()\n",
    "threshold = 850\n",
    "while True:\n",
    "    # # feed from default camera\n",
    "    # code,data = client.GetImageSample()\n",
    "    # img_1 = np.frombuffer(bytes(data), dtype=np.uint8)\n",
    "    # image_1 = cv2.imdecode(img_1, cv2.IMREAD_COLOR)\n",
    "    # image_1_rgb = cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        \n",
    "    tags_2 = detect_tag_from_main_camera()        \n",
    "    if tags_2:\n",
    "        max_bottom_left = 1080\n",
    "        found = False\n",
    "        for tag in tags_2:\n",
    "            if tag.center[1] < threshold:\n",
    "                found = True\n",
    "                print(\"found tag inside the box\")\n",
    "                move_randomly()\n",
    "                break\n",
    "        if not found:\n",
    "            print(\"no tag found\")\n",
    "            move_randomly(-0.1, 0, 0)\n",
    "            time.sleep(1)\n",
    "            move_randomly()\n",
    "    else:\n",
    "        move_randomly(-0.1, 0, 0)\n",
    "        time.sleep(1)\n",
    "        move_randomly()\n",
    "        \n",
    "    r = (np.random.random(3)-0.5)*0.8\n",
    "    move_randomly(*r)\n",
    "    \n",
    "    tags = detect_tag()\n",
    "    if len(tags_2) > 0:\n",
    "        print(sorted(tags_2))\n",
    "        # break\n",
    "    \n",
    "    if len(tags) > 0:\n",
    "        act(tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "343d0027-b3c7-466f-b620-90cbd36138ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659aebad-3c24-44f2-8c18-088a4da7a381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".jetbotenv",
   "language": "python",
   "name": ".jetbotenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
